# -*- coding: utf-8 -*-
"""RobotVisionProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VJUedBv-keartXyq3L1iU4oIEBmmCyHi
"""

!pip install opencv-contrib-python==4.4.0.44

import numpy as np
import cv2
import matplotlib.pyplot as plt
import glob
from google.colab.patches import cv2_imshow

objp = np.zeros((5*7,3), np.float32)
objp[:,:2] = np.mgrid[0:7,0:5].T.reshape(-1,2)

plt.scatter(objp[:, 0], objp[:, 1]);

# Arrays to store object points and image points from all the images.
objpoints = [] # 3d point in real world space
imgpoints = [] # 2d points in image plane.

# termination criteria
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# use images captured by camera
images = glob.glob('test*.jpg')

for fname in images:
    img = cv2.imread(fname)
    
    # Resize to make sure the image does not contain too much pixels for Opencv to find patterns

    img = cv2.resize(img, (640,480))
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    # Find the chess board corners, we use 8*6 grid
    ret, corners = cv2.findChessboardCorners(gray, (7,5),None)
    # If found, add object points, image points (after refining them)
    if ret == True:
      objpoints.append(objp)
      # cv2.cornerSubPix() increases the accuracy of the corner coordinates
      corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)
      imgpoints.append(corners2)
      # Draw and display the corners
      img = cv2.drawChessboardCorners(img, (7,5), corners2,ret)
      cv2_imshow(img)

# cv2.calibrateCamera() returns the camera matrix, distortion coefficients, rotation vectors, and translation vectors
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)

# print the values
print(mtx)
print(dist)
print(rvecs)
print(tvecs)

from google.colab.patches import cv2_imshow
from matplotlib.pyplot import imshow
from imutils import perspective
from imutils import contours
import numpy as np
import imutils
import math
import cv2

img = "6.jpg"

# Read image...
image = cv2.imread(img)

# Length and Height of Box
cv2.line(image, (298,77), (393,91),(255,0,0),3)
cv2.line(image, (298,77), (298,129),(255,0,0),3)
cv2.line(image, (298,129), (383,138),(255,0,0),3)
cv2.line(image, (393,91), (383, 138),(255,0,0),3)

# Length and Width of Box
cv2.line(image, (300,68), (308,40),(255,0,0),3)
cv2.line(image, (300,68), (393,82),(255,0,0),3)
cv2.line(image, (309,40), (394,48),(255,0,0),3)
cv2.line(image, (394,48), (393, 82),(255,0,0),3)

# Diameter and Height of Scroll
cv2.line(image, (120,128), (165,115),(255,0,0),3)
cv2.line(image, (120,128), (135,175),(255,0,0),3)
cv2.line(image, (165,115), (180,162),(255,0,0),3)
cv2.line(image, (180,162), (135, 175),(255,0,0),3)

hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# define range of blue color in HSV
lower_blue = np.array([110,35,35])
upper_blue = np.array([130,255,255])

# Threshold the HSV image to get only blueish colors
mask = cv2.inRange(hsv, lower_blue, upper_blue)

cv2_imshow(mask)

# Find contours in image
cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)

# Remove contours extra contours
cnts = [x for x in cnts if cv2.contourArea(x) > 200]

# Reference object dimensions
apriltag_img = cv2.imread(img)

# show the apriltag use matplotlib. If you use your local environment, you can use cv2.imshow() function as you did before
imshow(apriltag_img[:,:,::-1])

# load Tag36h11 in aruco dictionary
ARUCO_DICT = {"DICT_APRILTAG_36h11": cv2.aruco.DICT_APRILTAG_36h11}
arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT["DICT_APRILTAG_36h11"])

arucoParams = cv2.aruco.DetectorParameters_create()
(image_points, ids, rejected) = cv2.aruco.detectMarkers(apriltag_img, arucoDict,
	parameters=arucoParams)

# by default, the four corners are (x,y) coordinates in the image, with pixel as unit. 
# The order of the four corners are top-left, top-right, bottom-right, and bottom-left

# Ensure that at least one tag is detected, then prepare the corners for drawing:
if len(image_points) > 0:
	# flatten the ArUco IDs list
	ids = ids.flatten()
	# loop over the detected ArUCo corners
	for (markerCorner, markerID) in zip(image_points, ids):
		# extract the marker corners
		image_points = markerCorner.reshape((4, 2))
		(topLeft, topRight, bottomRight, bottomLeft) = image_points
		# convert each of the (x, y)-coordinate pairs to integers
		topRight = (int(topRight[0]), int(topRight[1]))
		bottomRight = (int(bottomRight[0]), int(bottomRight[1]))
		bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))
		topLeft = (int(topLeft[0]), int(topLeft[1]))
  
  # draw the bounding box of the ArUCo detection
cv2.line(apriltag_img, topLeft, topRight, (0, 255, 0), 4)
cv2.line(apriltag_img, topRight, bottomRight, (0, 255, 0), 4)
cv2.line(apriltag_img, bottomRight, bottomLeft, (0, 255, 0), 4)
cv2.line(apriltag_img, bottomLeft, topLeft, (0, 255, 0), 4)

# compute and draw the center (x, y)-coordinates of the ArUco marker
cX = int((topLeft[0] + bottomRight[0]) / 2.0)
cY = int((topLeft[1] + bottomRight[1]) / 2.0)
cv2.circle(apriltag_img, (cX, cY), 4, (0, 0, 255), -1)
# draw the ArUco marker ID on the image
cv2.putText(apriltag_img, str(markerID),
  (topLeft[0], topLeft[1] - 15), cv2.FONT_HERSHEY_SIMPLEX,
  3, (0, 255, 0), 2)
imshow(apriltag_img[:,:,::-1])

world_points = np.array([[0., 1., 0.], [1., 1., 0.], [1., 0., 0.], [0., 0., 0.]]) # ensure here we use float64 type, instead of int.
K = np.array([[496.83944364, 0.0, 439.59806822],
              [0.0, 495.76684561, 306.58791208],
							       [0.0, 0.0, 1.0]])

distorC = np.array([0.05805106,  0.20132603,  0.00184402,  0.00191373, -0.71333197])
_, rot, trans = cv2.solvePnP(world_points, image_points, K, distorC)

print(image_points)
draw_points_3d = [np.array([0., 1., 2.]), np.array([1., 1., 2.]), np.array([1., 0., 2.]), np.array([0., 0., 2.])]
draw_points_2d = []                                                                          
for i in range(len(draw_points_3d)):
  tmp = cv2.projectPoints(draw_points_3d[i], rot, trans, K, distorC)[0][0][0]  
  draw_points_2d.append(tmp) 

int_corners = np.int0(image_points)
cv2.polylines(image, [int_corners],True, (0, 255,0), 4)


distance_x = (image_points[0][0] - image_points[3][0])**2
distance_y = (image_points[0][1] - image_points[3][1])**2
distance_formula = math.sqrt(distance_x + distance_y)
pixel_ratio = (distance_formula) / (150.1) # ratio converson (pixel to mm)

# Draw remaining contours
for cnt in cnts: # for loop of contours...
	box = cv2.minAreaRect(cnt)
	(x,y), (w,h), angle = box

	obj_w = w / pixel_ratio # width
	obj_h = h / pixel_ratio # height

	box = cv2.boxPoints(box)
	box = np.int0(box)

	cv2.polylines(image, [box], True, (255, 0, 0), 2) 
	cv2.putText(image, "W = {:.1f} mm".format(round(obj_w),1), (int(x - 150), int(y - 25)),  cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255), 2)
	cv2.putText(image, "H = {:.1f} mm".format(round(obj_h,1)), (int(x - 150), int(y + 25)), cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255), 2)
 
cv2_imshow(image)